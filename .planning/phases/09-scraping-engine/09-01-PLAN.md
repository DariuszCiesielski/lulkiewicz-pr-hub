---
phase: 09-scraping-engine
plan: 01
type: execute
wave: 1
depends_on: []
files_modified:
  - src/lib/fb/apify-client.ts
  - src/lib/fb/post-mapper.ts
  - src/types/fb.ts
autonomous: true

must_haves:
  truths:
    - "Apify Actor run moze byc uruchomiony programatycznie z prawidlowym formatem inputu (cookie, groupUrl, scrapeUntil)"
    - "Status uruchomionego runu jest odpytywalny i poprawnie mapowany na akcje (keep_polling, fetch_results, mark_failed)"
    - "Wyniki z datasetu Apify sa pobierane i mapowane na struktury FbPost/FbComment z graceful fallbacks"
  artifacts:
    - path: "src/lib/fb/apify-client.ts"
      provides: "3 funkcje: startActorRun, getRunStatus, getDatasetItems"
      exports: ["startActorRun", "getRunStatus", "getDatasetItems", "mapApifyStatusToAction", "formatApifyDate"]
    - path: "src/lib/fb/post-mapper.ts"
      provides: "Mapowanie surowych danych Apify na typy FbPost/FbComment"
      exports: ["mapApifyPostToFbPost", "mapApifyCommentToFbComment", "extractFacebookPostId"]
    - path: "src/types/fb.ts"
      provides: "Nowe typy: ApifyCookieObject, ApifyActorInput, ApifyRunStatus, ScrapeConfig, ScrapeUIStatus, ScrapeProgress, ERROR_MESSAGES"
      contains: "ApifyCookieObject"
  key_links:
    - from: "src/lib/fb/apify-client.ts"
      to: "Apify REST API v2"
      via: "native fetch() with Bearer token"
      pattern: "fetch.*api\\.apify\\.com"
    - from: "src/lib/fb/post-mapper.ts"
      to: "src/types/fb.ts"
      via: "import FbPost, FbComment types"
      pattern: "import.*from.*@/types/fb"
---

<objective>
Backend foundation dla scraping engine: Apify API wrapper, post mapper i typy TS.

Purpose: Plan 01 tworzy warstwe abstrakcji nad Apify REST API v2 oraz mapowanie surowych danych aktora na typy domenowe FbPost/FbComment. Te moduly beda importowane przez API routes w Planie 02.

Output: 3 pliki - apify-client.ts (3 funkcje API), post-mapper.ts (mapowanie danych), rozszerzone fb.ts (nowe typy scrape).
</objective>

<execution_context>
@C:\Users\dariu\.claude/get-shit-done/workflows/execute-plan.md
@C:\Users\dariu\.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/09-scraping-engine/09-RESEARCH.md

@src/types/fb.ts
@src/lib/crypto/encrypt.ts
@src/lib/api/admin.ts
@src/app/api/fb-settings/route.ts
</context>

<tasks>

<task type="auto">
  <name>Task 1: Typy TS scrape + Apify API wrapper</name>
  <files>src/types/fb.ts, src/lib/fb/apify-client.ts</files>
  <action>
**1) Rozszerz src/types/fb.ts** o nowe typy na koncu pliku (po istniejacych typach Phase 8):

```typescript
// --- Phase 9: Scraping Types ---

export interface ApifyCookieObject {
  domain: string;
  expirationDate?: number;
  hostOnly: boolean;
  httpOnly: boolean;
  name: string;
  path: string;
  sameSite: string | null;
  secure: boolean;
  session: boolean;
  storeId: string | null;
  value: string;
}

export interface ApifyActorInput {
  cookie: ApifyCookieObject[];
  'scrapeGroupPosts.groupUrl': string;
  scrapeUntil: string;  // yyyy-M-dd (BEZ leading zero!)
  sortType: 'new_posts';
  minDelay: number;
  maxDelay: number;
  proxy: { useApifyProxy: boolean };
}

export interface ApifyRunStatusResponse {
  id: string;
  status: ApifyRunState;
  statusMessage: string | null;
  defaultDatasetId: string;
  startedAt: string | null;
  finishedAt: string | null;
}

export type ApifyRunState =
  | 'READY' | 'RUNNING' | 'SUCCEEDED' | 'FAILED'
  | 'TIMING-OUT' | 'TIMED-OUT' | 'ABORTING' | 'ABORTED';

export type ApifyStatusAction = 'keep_polling' | 'fetch_results' | 'mark_failed';

export interface ScrapeConfig {
  token: string;
  cookies: ApifyCookieObject[];
  actorId: string;
  groupUrl: string;
}

export type ScrapeUIStatus =
  'idle' | 'starting' | 'cookie_check' | 'running' | 'downloading' | 'completed' | 'error';

export interface ScrapeProgress {
  currentGroup: string | null;
  groupsTotal: number;
  groupsCompleted: number;
  postsFound: number;
  postsNew: number;
  postsUpdated: number;
  apifyStatus: string | null;
  estimatedWaitSeconds: number | null;
}

export interface ScrapeErrorInfo {
  message: string;
  suggestion: string;
}

// Mapowanie bledow Apify na komunikaty PL
export const SCRAPE_ERROR_MESSAGES: Record<string, ScrapeErrorInfo> = {
  'TIMED-OUT': {
    message: 'Scrapowanie przekroczylo limit czasu Apify',
    suggestion: 'Sprobuj ponownie. Jesli blad sie powtarza, zmniejsz zakres dat.',
  },
  'FAILED': {
    message: 'Apify Actor zakonczyl sie bledem',
    suggestion: 'Sprawdz logi w konsoli Apify. Moze byc problem z cookies lub proxy.',
  },
  'ABORTED': {
    message: 'Scrapowanie zostalo przerwane',
    suggestion: 'Run zostal recznie zatrzymany lub przekroczyl limit pamieci.',
  },
  'NO_TOKEN': {
    message: 'Brak skonfigurowanego tokenu Apify',
    suggestion: 'Przejdz do Ustawienia > Apify API Token i wklej swoj token.',
  },
  'NO_COOKIES': {
    message: 'Brak skonfigurowanych cookies Facebook',
    suggestion: 'Przejdz do Ustawienia > Facebook Cookies i wklej cookies z Cookie-Editor.',
  },
  'COOKIES_EXPIRED': {
    message: 'Cookies Facebook prawdopodobnie wygasly',
    suggestion: 'Zaloguj sie na dedykowane konto FB, wyeksportuj nowe cookies z Cookie-Editor i wklej w Ustawienia.',
  },
  'RATE_LIMITED': {
    message: 'Zbyt czeste scrapowanie — odczekaj przed kolejna proba',
    suggestion: 'Poczekaj minimum 3 minuty miedzy scrapowaniami roznych grup.',
  },
};
```

**2) Utworz src/lib/fb/apify-client.ts** z 3 funkcjami API + helperami:

- `startActorRun(token, actorId, input)` - POST /v2/acts/{actorId}/runs. Auth: `Authorization: Bearer {token}`. Body: actor input JSON. Zwraca `{ runId, datasetId }` z `json.data`. Rzuca Error na !res.ok (wlacz tresc odpowiedzi w komunikacie bledu).

- `getRunStatus(token, runId)` - GET /v2/actor-runs/{runId}. Auth: Bearer. Zwraca `ApifyRunStatusResponse` z `json.data`. Rzuca Error na !res.ok.

- `getDatasetItems<T>(token, datasetId, offset?, limit?)` - GET /v2/datasets/{datasetId}/items?format=json&offset={offset}&limit={limit}. Auth: Bearer. UWAGA: response to BEZPOSREDNI JSON ARRAY (NIE opakowany w data!). Total z headera `X-Apify-Pagination-Total`. Zwraca `{ items: T[], total: number }`. Default limit=1000.

- `mapApifyStatusToAction(status: ApifyRunState): ApifyStatusAction` - switch/case mapujacy WSZYSTKIE 8 statusow Apify: READY/RUNNING/TIMING-OUT/ABORTING -> keep_polling, SUCCEEDED -> fetch_results, FAILED/TIMED-OUT/ABORTED -> mark_failed.

- `formatApifyDate(date: Date): string` - formatuje date jako `yyyy-M-dd` (BEZ leading zero na miesiacu i dniu!). Uzyj `date.getFullYear()`, `date.getMonth() + 1`, `date.getDate()` bez padStart.

APIFY_BASE = `https://api.apify.com/v2`

Plik jest SERVER-ONLY (tokeny sa sekretem). Dodaj komentarz na gorze `// Server-only — NIE importuj w komponentach klienckich`.
  </action>
  <verify>
  - `npx tsc --noEmit` — brak bledow kompilacji
  - Grep: `startActorRun`, `getRunStatus`, `getDatasetItems` eksportowane z apify-client.ts
  - Grep: `ApifyCookieObject`, `ScrapeConfig`, `SCRAPE_ERROR_MESSAGES` eksportowane z fb.ts
  </verify>
  <done>apify-client.ts eksportuje 5 funkcji (startActorRun, getRunStatus, getDatasetItems, mapApifyStatusToAction, formatApifyDate), fb.ts zawiera 10+ nowych typow i stala SCRAPE_ERROR_MESSAGES. Kompilacja TS przechodzi bez bledow.</done>
</task>

<task type="auto">
  <name>Task 2: Post mapper z graceful fallbacks</name>
  <files>src/lib/fb/post-mapper.ts</files>
  <action>
Utworz `src/lib/fb/post-mapper.ts` z funkcjami mapujacymi surowe dane z Apify Actor na typy DB.

**Potwierdzone pola z N8N workflow:** `createdAt`, `url`, `text`. Reszta pol (author, reactions, comments, images) ma MEDIUM confidence — mapper MUSI obsluzyc ich brak gracefully.

1) `extractFacebookPostId(url: string): string` — Wyciaga unikalny identyfikator posta z URL-a.
   - Probuj pattern: `/groups/{groupId}/posts/{postId}` -> zwroc `{postId}`
   - Probuj pattern: `/permalink/{postId}` -> zwroc `{postId}`
   - Probuj pattern: `story_fbid={id}` w query params -> zwroc `{id}`
   - Fallback: uzywaj calego URL jako ID (nigdy nie zwracaj pustego stringa)
   - Loguj warning na fallback: `console.warn('Could not extract post ID from URL, using full URL:', url)`

2) `mapApifyPostToFbPost(raw: Record<string, unknown>, groupId: string): MappedFbPost` gdzie:
   ```typescript
   interface MappedFbPost {
     group_id: string;
     facebook_post_id: string;
     author_name: string | null;
     content: string | null;
     posted_at: string | null;
     likes_count: number;
     comments_count: number;
     shares_count: number;
     post_url: string | null;
     media_url: string | null;
   }
   ```

   Mapowanie pol (z fallbackami):
   - `facebook_post_id`: `extractFacebookPostId(raw.url as string)` jesli `raw.url` istnieje, inaczej `raw.postId || raw.id || crypto.randomUUID()`
   - `author_name`: `raw.authorName || raw.author_name || raw.author || null`
   - `content`: `raw.text || raw.content || raw.message || null`
   - `posted_at`: jesli `raw.createdAt` istnieje, sparsuj do ISO string. Uzyj `new Date(raw.createdAt as string).toISOString()`. Wrap w try/catch, na bledzie zwroc null.
   - `likes_count`: `Number(raw.likes ?? raw.likesCount ?? raw.reactions ?? 0)`
   - `comments_count`: `Number(raw.comments ?? raw.commentsCount ?? 0)`
   - `shares_count`: `Number(raw.shares ?? raw.sharesCount ?? 0)`
   - `post_url`: `(raw.url as string) || null`
   - `media_url`: `(raw.image as string) || (raw.imageUrl as string) || ((raw.images as string[])?.[0]) || null`

3) `mapApifyCommentToFbComment(raw: Record<string, unknown>, postId: string): MappedFbComment | null` gdzie:
   ```typescript
   interface MappedFbComment {
     post_id: string;
     facebook_comment_id: string;
     author_name: string | null;
     content: string | null;
     posted_at: string | null;
   }
   ```
   Zwroc `null` jesli `raw.text` i `raw.content` sa puste (pomijamy puste komentarze).
   `facebook_comment_id`: `raw.commentId || raw.id || crypto.randomUUID()`

4) Dodaj na gorze pliku: `// Surowe pola aktora maja MEDIUM confidence. Mapper obsluguje brak pol gracefully.`
5) Dodaj debug helper: `export function logRawPostSample(items: Record<string, unknown>[], count = 3): void` — loguje `console.log('Apify raw post sample:', JSON.stringify(items.slice(0, count), null, 2))`. Ten helper bedzie wywolany przy pierwszym scrapowaniu zeby zweryfikowac faktyczny schemat outputu.

Eksportuj oba interfejsy (MappedFbPost, MappedFbComment) i wszystkie 4 funkcje.
  </action>
  <verify>
  - `npx tsc --noEmit` — brak bledow kompilacji
  - Grep: `mapApifyPostToFbPost`, `extractFacebookPostId`, `logRawPostSample` eksportowane
  - Grep: `MappedFbPost` interface zawiera `facebook_post_id`, `post_url`, `media_url`
  </verify>
  <done>post-mapper.ts eksportuje 4 funkcje i 2 interfejsy. extractFacebookPostId obsluguje 3 patterny URL + fallback. mapApifyPostToFbPost mapuje 10 pol z graceful fallbacks. Kompilacja TS przechodzi.</done>
</task>

</tasks>

<verification>
- `npx tsc --noEmit` przechodzi bez bledow
- Pliki `src/lib/fb/apify-client.ts` i `src/lib/fb/post-mapper.ts` istnieja i eksportuja wszystkie wymienione funkcje
- `src/types/fb.ts` zawiera nowe typy Phase 9 (ApifyCookieObject, ScrapeConfig, SCRAPE_ERROR_MESSAGES itd.)
- Zadne istniejace importy nie sa zlamane (fb.ts rozszerzony, nie zmieniony)
</verification>

<success_criteria>
1. apify-client.ts ma 3 funkcje API + 2 helpery, poprawne URL-e Apify v2, Bearer auth
2. post-mapper.ts mapuje surowe dane na FbPost/FbComment z fallbackami na kazde pole
3. fb.ts ma 10+ nowych typow i const SCRAPE_ERROR_MESSAGES
4. `npx tsc --noEmit` przechodzi
</success_criteria>

<output>
After completion, create `.planning/phases/09-scraping-engine/09-01-SUMMARY.md`
</output>
