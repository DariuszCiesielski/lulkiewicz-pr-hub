---
phase: 09-scraping-engine
plan: 03
type: execute
wave: 3
depends_on: ["09-02"]
files_modified:
  - src/hooks/useScrapeJob.ts
  - src/components/fb/ScrapeProgress.tsx
  - src/components/fb/ScrapeButton.tsx
  - src/components/fb/GroupTable.tsx
  - src/app/(hub)/fb-analyzer/groups/page.tsx
autonomous: true

must_haves:
  truths:
    - "Admin klika przycisk Scrapuj na aktywnej grupie — progress bar pokazuje status w czasie rzeczywistym"
    - "Scrapowanie wielu grup wymusza 180-360s przerwy miedzy grupami z informacja o kolejce w UI"
    - "Bledy scrapowania sa wyswietlane z polskim komunikatem i sugestia rozwiazania"
    - "Po zakonczeniu scrapowania lista grup odswieza sie (aktualizacja last_scraped_at, total_posts)"
    - "Cookie health check ostrzega przed scrapowaniem jesli cookies moga byc wygasle"
  artifacts:
    - path: "src/hooks/useScrapeJob.ts"
      provides: "Hook pollingowy z multi-group queue i rate limiting"
      exports: ["useScrapeJob"]
    - path: "src/components/fb/ScrapeProgress.tsx"
      provides: "Komponent progress bar z statusem scrapowania"
      exports: ["default"]
    - path: "src/components/fb/ScrapeButton.tsx"
      provides: "Przycisk Scrapuj per grupa z loading state"
      exports: ["default"]
    - path: "src/components/fb/GroupTable.tsx"
      provides: "Tabela grup z dodanym przyciskiem Scrapuj w kolumnie akcji"
      contains: "ScrapeButton"
    - path: "src/app/(hub)/fb-analyzer/groups/page.tsx"
      provides: "Strona grup z zintegrowanym useScrapeJob i ScrapeProgress"
      contains: "useScrapeJob"
  key_links:
    - from: "src/hooks/useScrapeJob.ts"
      to: "/api/fb/scrape"
      via: "fetch POST to start job"
      pattern: "fetch.*api/fb/scrape"
    - from: "src/hooks/useScrapeJob.ts"
      to: "/api/fb/scrape/process"
      via: "fetch POST polling loop"
      pattern: "fetch.*api/fb/scrape/process"
    - from: "src/app/(hub)/fb-analyzer/groups/page.tsx"
      to: "src/hooks/useScrapeJob.ts"
      via: "import useScrapeJob hook"
      pattern: "import.*useScrapeJob"
---

<objective>
Frontend scraping: hook pollingowy, komponenty UI, integracja z tabela grup.

Purpose: Plan 03 zamyka petle UI scraping engine. useScrapeJob hook zarzadza lifecycle scrapowania (pojedynczego i bulk), ScrapeProgress pokazuje postep, ScrapeButton triggeruje per grupa. Integracja z istniejaca tabela grup dodaje przycisk "Scrapuj" per wiersz.

Output: Hook + 2 nowe komponenty + modyfikacja GroupTable i groups/page.tsx.
</objective>

<execution_context>
@C:\Users\dariu\.claude/get-shit-done/workflows/execute-plan.md
@C:\Users\dariu\.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/09-scraping-engine/09-RESEARCH.md
@.planning/phases/09-scraping-engine/09-02-SUMMARY.md

@src/hooks/useSyncJob.ts
@src/components/fb/GroupTable.tsx
@src/app/(hub)/fb-analyzer/groups/page.tsx
@src/types/fb.ts
</context>

<tasks>

<task type="auto">
  <name>Task 1: useScrapeJob hook z multi-group queue</name>
  <files>src/hooks/useScrapeJob.ts</files>
  <action>
Utworz `src/hooks/useScrapeJob.ts` — hook pollingowy wzorowany na useSyncJob.ts ale z kluczowymi roznciami:

1) **Polling interval: 5000ms** (nie 500ms jak w useSyncJob). Apify runy trwaja minuty, nie sekundy.

2) **Status flow:** idle -> starting -> running -> downloading -> completed/error
   (cookie_check pomijamy w v1 — health check bedzie ostrzezeniem, nie blokerem)

3) **Interface:**
```typescript
'use client';

import { useState, useCallback, useRef } from 'react';
import type { ScrapeUIStatus, ScrapeProgress, ScrapeErrorInfo, SCRAPE_ERROR_MESSAGES } from '@/types/fb';

export interface UseScrapeJobReturn {
  startScrape: (groupId: string, groupName?: string) => Promise<void>;
  startBulkScrape: (groups: Array<{ id: string; name: string }>) => Promise<void>;
  status: ScrapeUIStatus;
  progress: ScrapeProgress;
  error: ScrapeErrorInfo | null;
  jobId: string | null;
  reset: () => void;
}
```

4) **startScrape(groupId, groupName?):**
   - Reset state, ustawiaj status = 'starting'
   - POST /api/fb/scrape z { groupId }
   - Na error: ustawiaj status = 'error', error z SCRAPE_ERROR_MESSAGES jesli dostepne, inaczej generic { message, suggestion }
   - Na sukces: zapisz jobId, ustawiaj status = 'running', startuj polling loop

5) **Polling loop (processScrape):**
   - POST /api/fb/scrape/process z { jobId }
   - Parse response:
     - `data.status === 'running'`: ustawiaj progress.apifyStatus = data.apifyStatus, czekaj 5000ms, powtorz
     - `data.status === 'downloading'`: ustawiaj status = 'downloading', aktualizuj postsFound/postsNew/postsUpdated z response, czekaj 2000ms (szybciej na download), powtorz
     - `data.status === 'completed'`: ustawiaj status = 'completed', finalne wartosci progress, wywolaj onComplete callback
     - `data.status === 'failed'`: ustawiaj status = 'error', parsuj error z response (data.error jako ScrapeErrorInfo)
     - `data.hasMore === true`: kontynuuj polling
   - Na fetch error: ustawiaj status = 'error', error = generic connection error

6) **startBulkScrape(groups):**
   - Ustawiaj progress.groupsTotal = groups.length
   - Iteruj sekwencyjnie po grupach:
     a) Ustawiaj progress.currentGroup = group.name, progress.groupsCompleted = i
     b) Wywolaj startScrape(group.id, group.name) i czekaj na zakonczenie (Promise)
     c) Jesli i < groups.length - 1 (nie ostatnia grupa):
        - Oblicz losowe opoznienie: MIN_DELAY + Math.random() * (MAX_DELAY - MIN_DELAY)
        - MIN_DELAY = 180 (3 min), MAX_DELAY = 360 (6 min)
        - Ustawiaj progress.estimatedWaitSeconds = delay
        - Ustawiaj status = 'idle' tymczasowo (albo nowy status 'waiting'... nie, uzyj 'idle' z estimatedWaitSeconds > 0 jako sygnalu czekania)
        - DECYZJA: dodaj do ScrapeUIStatus wartosc 'waiting' w typach? NIE — za duzo zmian. Zamiast tego uzyj pola `isWaitingBetweenGroups: boolean` w ScrapeProgress.
        - Aktualizacja: dodaj `isWaitingBetweenGroups: boolean` i `waitSecondsRemaining: number` do ScrapeProgress w fb.ts (Task 1 doda te pola).
        - Ustawiaj progress.isWaitingBetweenGroups = true, uruchom countdown timer co 1s zmniejszajacy waitSecondsRemaining
        - Po uplywie delay: progress.isWaitingBetweenGroups = false, kontynuuj
   - Po zakonczeniu wszystkich: finalne status = 'completed'

   UWAGA: startBulkScrape tworzy OSOBNY job per grupe (sekwencyjnie). Kazdy job to pelny cykl start->poll->fetch. Miedzy grupami wymuszony delay 180-360s.

7) **Refs i cleanup:**
   - timeoutRef do clearTimeout on unmount
   - mountedRef do ignorowania updateow po unmount
   - onCompleteRef do unikniecia stale closure (wzorzec z useSyncJob)
   - WAZNE: useEffect cleanup ktory ustawia mountedRef.current = false i clearuje timeout

8) **Pola progress inicjalizowane na:**
   ```
   { currentGroup: null, groupsTotal: 0, groupsCompleted: 0, postsFound: 0, postsNew: 0, postsUpdated: 0, apifyStatus: null, estimatedWaitSeconds: null, isWaitingBetweenGroups: false, waitSecondsRemaining: 0 }
   ```

DODATKOWE ZMIANY w src/types/fb.ts:
- Dodaj `isWaitingBetweenGroups: boolean` i `waitSecondsRemaining: number` do interfejsu ScrapeProgress (na koncu, po `estimatedWaitSeconds`)

Podpis hooka: `export function useScrapeJob(onComplete?: () => void): UseScrapeJobReturn`
  </action>
  <verify>
  - `npx tsc --noEmit` — brak bledow
  - Grep: `useScrapeJob` eksportowane z hooks/useScrapeJob.ts
  - Grep: `startScrape`, `startBulkScrape`, `reset` w eksportach hooka
  - Grep: `api/fb/scrape` — fetch do obu endpointow
  - Grep: `180.*360\|MIN_DELAY\|MAX_DELAY` — rate limiting 3-6 min
  - Grep: `5000` — polling interval 5s
  </verify>
  <done>useScrapeJob hook eksportuje startScrape (single), startBulkScrape (multi z 180-360s delay), status, progress, error, jobId, reset. Polling co 5s. Rate limiting wymuszony klient-side. Cleanup na unmount.</done>
</task>

<task type="auto">
  <name>Task 2: Komponenty UI + integracja z tabela grup</name>
  <files>src/components/fb/ScrapeProgress.tsx, src/components/fb/ScrapeButton.tsx, src/components/fb/GroupTable.tsx, src/app/(hub)/fb-analyzer/groups/page.tsx</files>
  <action>
**1) Utworz `src/components/fb/ScrapeProgress.tsx`** — komponent progress bar:

```
Props: { status: ScrapeUIStatus; progress: ScrapeProgress; error: ScrapeErrorInfo | null; onRetry?: () => void; onReset: () => void; }
```

Renderowanie warunkowe na podstawie status:
- `idle`: nie renderuj nic (return null)
- `starting`: spinner + "Rozpoczynanie scrapowania..."
- `running`: spinner + "Scrapowanie w toku..." + progress.apifyStatus (jesli dostepny) + jesli progress.groupsTotal > 1: "Grupa {groupsCompleted+1}/{groupsTotal}: {currentGroup}"
- `downloading`: progress bar (animated) + "Pobieranie wynikow... {postsFound} postow" + postsNew/postsUpdated counts
- `completed`: ikona CheckCircle2 (zielona) + "Scrapowanie zakonczone" + statystyki (postsFound postow, {postsNew} nowych, {postsUpdated} zaktualizowanych) + przycisk "OK" (onReset)
- `error`: ikona AlertTriangle (czerwona) + error.message + error.suggestion (mniejszy tekst) + przycisk "Sprobuj ponownie" (onRetry) + przycisk "Zamknij" (onReset)

Jesli progress.isWaitingBetweenGroups:
- Timer countdown: "Oczekiwanie {waitSecondsRemaining}s przed kolejna grupa... ({currentGroup})"
- Pasek postepu z animacja countdown

Styl: CSS variables (--bg-secondary, --border-primary, --text-primary, --text-muted, --accent-primary). Wzorzec z istniejacych komponentow FB. Lucide icons.

Kontener: div z rounded-lg border p-4, sticky top-0 z-10 (widoczny podczas scrollowania tabeli).

**2) Utworz `src/components/fb/ScrapeButton.tsx`** — przycisk per grupa:

```
Props: { group: FbGroupEnriched; isScrapingAny: boolean; currentScrapingGroupId: string | null; onScrape: (groupId: string) => void; }
```

- Jesli `group.status === 'paused'`: nie renderuj (grupy wstrzymane nie moga byc scrapowane)
- Jesli `isScrapingAny && currentScrapingGroupId === group.id`: spinner (Loader2 animate-spin) + "Scrapuje..."
- Jesli `isScrapingAny && currentScrapingGroupId !== group.id`: disabled button, opacity-50
- Jesli `!isScrapingAny`: normalny przycisk "Scrapuj" z ikona Download (lucide-react)
- Kolor: text-blue-500/accent-primary, hover:opacity-80
- Rozmiar: maly (h-4 w-4 ikona, text-xs tekst), pasujacy do wiersza tabeli
- onClick: onScrape(group.id)
- title: "Scrapuj posty z tej grupy"

**3) Zmodyfikuj `src/components/fb/GroupTable.tsx`:**

Dodaj prop `onScrape` i stany scrapowania do interfejsu:

```typescript
interface GroupTableProps {
  // istniejace props...
  onScrape?: (group: FbGroupEnriched) => void;
  isScrapingAny?: boolean;
  currentScrapingGroupId?: string | null;
}
```

W kolumnie "Akcje" dodaj ScrapeButton PRZED przyciskiem Toggle Status (pierwszy w rzedzie akcji):
```tsx
{onScrape && (
  <ScrapeButton
    group={group}
    isScrapingAny={isScrapingAny || false}
    currentScrapingGroupId={currentScrapingGroupId || null}
    onScrape={() => onScrape(group)}
  />
)}
```

Import ScrapeButton z `@/components/fb/ScrapeButton`.

**4) Zmodyfikuj `src/app/(hub)/fb-analyzer/groups/page.tsx`:**

a) Import useScrapeJob:
```typescript
import { useScrapeJob } from '@/hooks/useScrapeJob';
import ScrapeProgress from '@/components/fb/ScrapeProgress';
```

b) Dodaj hook w komponencie:
```typescript
const {
  startScrape,
  startBulkScrape,
  status: scrapeStatus,
  progress: scrapeProgress,
  error: scrapeError,
  jobId: scrapeJobId,
  reset: scrapeReset,
} = useScrapeJob(() => refreshGroups());
```

c) Handler scrape per grupa:
```typescript
const handleScrapeGroup = useCallback(async (group: FbGroupEnriched) => {
  await startScrape(group.id, group.name);
}, [startScrape]);
```

d) Handler bulk scrape (wybranych grup):
```typescript
const handleBulkScrape = useCallback(async () => {
  const activeGroups = filteredGroups
    .filter(g => selectedIds.has(g.id) && g.status === 'active')
    .map(g => ({ id: g.id, name: g.name }));
  if (activeGroups.length === 0) {
    setError('Brak aktywnych grup do scrapowania');
    return;
  }
  setSelectedIds(new Set());
  await startBulkScrape(activeGroups);
}, [filteredGroups, selectedIds, startBulkScrape]);
```

e) Dodaj ScrapeProgress miedzy error banner a BulkActionToolbar:
```tsx
{scrapeStatus !== 'idle' && (
  <ScrapeProgress
    status={scrapeStatus}
    progress={scrapeProgress}
    error={scrapeError}
    onRetry={() => {
      const currentGroup = scrapeProgress.currentGroup;
      scrapeReset();
      // retry logic jesli jest grupa
    }}
    onReset={scrapeReset}
  />
)}
```

f) Przekaz props do GroupTable:
```tsx
<GroupTable
  // istniejace props...
  onScrape={handleScrapeGroup}
  isScrapingAny={scrapeStatus !== 'idle' && scrapeStatus !== 'completed' && scrapeStatus !== 'error'}
  currentScrapingGroupId={/* wyciagnij z progress.currentGroup matching */}
/>
```

UWAGA: currentScrapingGroupId wymaga mapowania z nazwy grupy na ID. Dodaj state `scrapingGroupId` w page.tsx ktory jest ustawiany w handleScrapeGroup.

g) Dodaj przycisk "Scrapuj wybrane" w headerze obok "Dodaj grupe" (jesli selectedIds.size > 0):
```tsx
{selectedIds.size > 0 && (
  <button
    onClick={handleBulkScrape}
    disabled={scrapeStatus !== 'idle' && scrapeStatus !== 'completed' && scrapeStatus !== 'error'}
    className="flex items-center gap-1 rounded-md px-3 py-1.5 text-sm text-white transition-colors hover:opacity-90 disabled:opacity-50"
    style={{ backgroundColor: '#3b82f6' }}
  >
    <Download className="h-4 w-4" />
    Scrapuj wybrane ({selectedIds.size})
  </button>
)}
```

Import Download z lucide-react.

h) Cookie health check ostrzezenie: Na stronie grup dodaj proste ostrzezenie jesli ostatni scrape dowolnej grupy (ktora miala posty) zwrocil 0 nowych postow. To moze sugerowac wygasle cookies. Wyswietl zolty banner z SCRAPE_ERROR_MESSAGES['COOKIES_EXPIRED'].suggestion. Logika:
- Przy fetchData() sprawdz czy sa grupy z total_posts > 0 ale last_scraped_at starszy niz 7 dni -> NIE, to za skomplikowane. Zamiast tego:
- Po zakonczeniu scrapowania (onComplete), jesli postsFound === 0 i grupa miala wczesniej posty (total_posts > 0), wyswietl ostrzezenie o cookies.
- PROSTSZE: W ScrapeProgress, jesli status === 'completed' && postsFound === 0, pokazuj zolty alert "Nie znaleziono nowych postow. Jesli grupa jest aktywna, moze to oznaczac wygasle cookies."
  </action>
  <verify>
  - `npx tsc --noEmit` — brak bledow
  - `npm run build` — buduje bez bledow (weryfikacja SSR kompatybilnosci)
  - Pliki istnieja: src/hooks/useScrapeJob.ts, src/components/fb/ScrapeProgress.tsx, src/components/fb/ScrapeButton.tsx
  - Grep: `useScrapeJob` importowane w groups/page.tsx
  - Grep: `ScrapeButton` importowane w GroupTable.tsx
  - Grep: `ScrapeProgress` importowane w groups/page.tsx
  - Grep: `onScrape` w interfejsie GroupTableProps
  - Grep: `startBulkScrape` uzyte w groups/page.tsx
  - Grep: `180.*1000\|MIN_DELAY_MS\|180000` — delay 3min miedzy grupami w hooku
  </verify>
  <done>useScrapeJob hook zintegrowany z groups/page.tsx. ScrapeButton per wiersz w GroupTable. ScrapeProgress sticky na gorze strony. Bulk scrape z selectedIds. Rate limiting 180-360s miedzy grupami. Ostrzezenie o cookies jesli 0 postow. Build przechodzi.</done>
</task>

</tasks>

<verification>
- `npx tsc --noEmit` przechodzi
- `npm run build` przechodzi
- Hook useScrapeJob eksportuje startScrape, startBulkScrape, status, progress, error, reset
- ScrapeProgress pokazuje statusy: starting, running, downloading, completed, error, waiting between groups
- ScrapeButton renderuje sie per aktywna grupa w tabeli
- GroupTable przyjmuje onScrape, isScrapingAny, currentScrapingGroupId
- groups/page.tsx integruje hook + progress + scrape handlers
- Rate limiting: 180-360s miedzy grupami w bulk scrape
- Cookie warning: alert jesli 0 postow po scrapowaniu
</verification>

<success_criteria>
1. Admin widzi przycisk "Scrapuj" per aktywna grupa w tabeli
2. Klikniecie "Scrapuj" startuje pipeline (idle -> starting -> running -> downloading -> completed)
3. Progress bar pokazuje aktualny status z informacja o postach
4. Bulk scrape z wybranych grup dziala z 180-360s przerwami i informacja o kolejce
5. Bledy sa wyswietlane z polskim komunikatem i sugestia
6. Ostrzezenie o cookies jesli scrapowanie zwroci 0 postow
7. Po zakonczeniu lista grup odswieza sie (total_posts, last_scraped_at)
8. Build przechodzi bez bledow
</success_criteria>

<output>
After completion, create `.planning/phases/09-scraping-engine/09-03-SUMMARY.md`
</output>
